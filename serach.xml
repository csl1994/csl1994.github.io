<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[SIFT]]></title>
    <url>%2F2018%2F06%2F13%2Fsift%2F</url>
    <content type="text"><![CDATA[Scale-space Extrema Detection在这个阶段，主要是侦测兴趣点，也就是SIFT架构中的关键点。 1.1 尺度空间：高斯模糊$G(x,y,k\sigma)=\frac{1}{2\pi\sigma^2}e^{-(x^2+y^2)/2\sigma^2}$与原图$I(x,y)$的乘积 L(x,y,k\sigma)=G(x,y,k\sigma)*I(x,y)模糊与特征的关系 1.2 图像金字塔：为了$\underline{尺度}$不变性，形成的方式是降采样（每一层面积为之前的四分之一），如下图$在同一层的高斯模糊的倍率逐渐增大(\sigma,k\sigma,k^2\sigma…)，每一层是前一层倍率的2倍。$1.3 DoG(Difference of Gaussian）：$D(x,y,\sigma)=L(x,y,k_{i}\sigma)-L(x,y,k_{j}\sigma)$形成高斯差图像之后，对比每个像素周围的8个点，以及同一层不同倍率的相邻的图像的18个点，共26个点。若此像素值为极值则是关键点，如下图$注意：$SIFT算法中关键点的侦测是一种斑点检测(Blob detection)的一种变形，也就是使用拉普拉斯算子来求出各个倍率及空间中的最大值。高斯差可近似为拉普拉斯算子运算后的结果，因建立高斯金字塔的过程是一种尺寸正规化拉普拉斯运算的近似。DoG近似LoG Keypoint Localization2.1 前一章是从27个点中选取的极值所以不是连续的，精确的定位需要进行连续形式的变换。就需要在上一步检测的位置进行泰勒展开 D(x) = D+\frac{\partial D^T}{\partial x}x+\frac{1}{2}x^T\frac{\partial ^2D}{\partial x}x,x=(x,y,\sigma)是到此关键点的偏移量求出极值点$\hat x$若结果任意参数大于0.5，则替换重新计算，反之结束 2.2 筛选若$D(\hat x)$大于0.03则保留，否则舍弃 2.3 消除边缘响应横跨边缘的主曲率大或者垂直边缘的主曲率小，则DoG不太适合，关键点主曲率可解为二次Hessian矩阵的特征值 H=\left [ \begin{matrix} D_{xx}&D_{xy}\\ D_{xy}&D_{yy} \end{matrix}\right],假设特征值为\alpha和\beta为了避免特征值的计算，有$Tr(H)=\alpha+\beta,Det(H)=\alpha\beta$，计算 R=\frac{Tr(H)^2}{Det(H)}=\frac{(\alpha+\beta)^2}{\alpha\beta}=\frac{(r+1)^2}{r}，其中r=\alpha/\beta依据函数的性质可知在$\alpha=\beta$时有最小值，当$r&gt;1$且逐渐增大时，函数值逐渐增大，因此设阈值$r_{t}$，当$R&gt;(r_t+1)^2/r_t$时舍去关键点。 Orientation Assignment3.1 依据公式计算出关键点邻域像素的幅值和幅角 m(x,y)=\sqrt{(L(x+1,y)-L(x-1,y))^2+(L(x,y+1)-L(x,y-1))^2}\theta(x,y)=atan2((L(x,y+1)-L(x,y-1),L(x+1,y)-L(x-1,y))将圆周以10°（45°）为单位划分36（8）等份统计直方图（横轴为方向角，纵轴为幅值累加），将最大值作为此关键点的主方向，若是最值与局部极值相差20%以内则为辅方向。幅值、幅角 Keypoint Descriptor4.1 将3中关键点的邻域的x轴旋转与主方向一致，保证特征的$\underline{方向}$不变性。以4$$4的区域的8个方向的梯度直方图为一个种子点，在关键点周围16$$16的区域共有4$$4$$8个数据。最后进行归一化处理，除去光照影响。 Keypoint Matching]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>image retrieval</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[乱]]></title>
    <url>%2F2018%2F06%2F12%2F%E4%B9%B1%2F</url>
    <content type="text"><![CDATA[感觉脑子有点乱从来到实验室到现在有两个多月的时间。先是在C区5楼看马新柱之前的工作（大多是一些网络结构的论文）和深度学习的基础知识（conv、pooling、BP、loss）之类的东西，期间还去参加了valse2018，这一段时间感觉挺充实的学到的东西也比较多，谈不上特别深刻，但是对于CNN在自己的脑海中有了一个成型的认识。在五一之后，开始看一些检索的论文。感觉一切都是从头开始，因为个人认为之前关于网络结构的论文对于检索的理解没有很大的帮助，所以没有知识的累积起步特别困难。检索的相关有一个比赛，在比赛中我负责的是标注数据~~~茫茫然。但是比赛毕竟是有分工的，而且分好的数据在训练之后取得的检测效果不错所以也比较满意。但是数据又要面临第二次处理，也就进入了六月。YOLOv3一个识别领域应用极为广泛的作品，我也开始学习了，因为不得其法所以论文看起来很费劲，但是应用完全是两个概念，虽然我用第二次处理的数据产生的训练效果不好但总算能用一用这个东西。如此乱也就来，分类-检测-检索我究竟干了啥？我自己能干啥？我想干啥？]]></content>
      <categories>
        <category>blog</category>
      </categories>
      <tags>
        <tag>note</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Principal Component Analysis]]></title>
    <url>%2F2018%2F05%2F31%2FPCA%2F</url>
    <content type="text"><![CDATA[协方差衡量两个变量的总体误差,从数值来看，协方差的数值越大，两个变量同向程度也就越大。反之亦然。公式 $Cov(X,Y)=E(X-E(X))(Y-E(Y)) =EXY-EXEY$ 协方差矩阵协方差矩阵的每个元素是各个向量元素之间的协方差，是一个对称非负正定矩阵。设$X=(X_{1},X_{2},…,X_{n})^T$为n维随机变量，则有协方差矩阵$C$如下： C=(c_{ij})_{n*n}=\left(\begin{matrix} c_{11} & c_{12} & \cdots & c_{1n}\\ c_{21} & c_{22} & \cdots & c_{2n}\\ \vdots & \vdots & \ddots & \vdots\\ c_{n1} & c_{n2} & \cdots & c_{nn}\\ \end{matrix} \right)其中，$c_{ij}=Cov(X_{i},X_{j}),i,j=1,2,…,n$ PCA是一种降维方法，PCA的思想是将$n$维的特征映射到$k$维的标准正交特征上1.将原始数据按行排列组成矩阵$X_{old}$2.对$X_{old}$进行数据标准化，使其均值变为零$X_{new}$3.求$X_{new}$的协方差矩阵$C,C=X_{new}X_{new}^T$4.将特征向量$\alpha$按特征值$\lambda$由大到小排列，取前$k$个按行组成矩阵$W$5.通过计算$Y=WX_{new}$，得到降维后数据$Y$ $\underline{分析}$：利用超平面对样本进行表达需要考虑两个性质(1)最近重构性，是指样本点到达平面的距离足够近；(2)最大可分性，是指样本点在超平面的投影尽可能的区分开；利用(2)，也就是$\sum_{i} D(Y_{i})$最大，即$\sum_{i}W^TX_{i}X_{i}^TW=\sum_{i}W^TC_{i}W$最大。协方差矩阵为实对称矩阵，且是半正定的，其对角线为$D(X_{i})$，所以能够相似对角化成$\lambda$组成的矩阵，故而将特征向量$\alpha$按特征值$\lambda$由大到小排列，取前$k$个按行组成矩阵$W$ PCA Whitening图片中相邻像素间有很强大的相关性，输入的数据有很多冗余的成分，白化处理可以消除这种冗余，PCA就是其中一种方法(ZCA)。白化操作使得(1)特征之间的相关性较低(2)特征的方差一致。步骤：采用PCA的方法(1)可以考虑取全部的特征向量，而不是前$k$个，这样就不会降维(PCA)(2)方差一致，计算公式为$X_{PCAwhite}=\frac{C}{\sqrt C}$，也可以$X_{PCAwhite}=\frac{C}{\sqrt {\lambda+\epsilon}}$，$\epsilon$为了避免$\lambda$过小]]></content>
      <categories>
        <category>deep learning</category>
      </categories>
      <tags>
        <tag>image retrieval</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[测试标题]]></title>
    <url>%2F2018%2F02%2F11%2F%E6%B5%8B%E8%AF%95%E6%96%87%E7%AB%A0%2F</url>
    <content type="text"><![CDATA[测试前言 测试正文测试第一段xxxxxx 测试第二段 yyyyyy 测试第三段zzzzzz 测试第四段1System.out.prient(&quot;hello world!&quot;); 测试第五段 测试第五段测试第六段这是一个测试链接 测试第六段 列表一 列表二]]></content>
      <categories>
        <category>test</category>
      </categories>
      <tags>
        <tag>note</tag>
      </tags>
  </entry>
</search>
